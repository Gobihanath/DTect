{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvp2MjFz2oxH96fQzzTY9n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gobihanath/DTect/blob/main/DTect_RestNet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnPH5L_f51Dl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\n",
        "from keras import layers, models, callbacks\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "\n",
        "input_shape = (256,256 , 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "dQH2CzFsGhE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25aa1827-7cc8-4344-a984-dfb846c3032b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image_Width = 256\n",
        "Image_Height = 256\n",
        "Image_Size = (Image_Width, Image_Height)\n",
        "Image_Channel = 3\n",
        "batch_size=128"
      ],
      "metadata": {
        "id": "fbvfPqrTGiDF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Dataset/Dtect | Dataset | New\",\n",
        "    seed=123,         #If you want to ensure that the shuffling of your dataset is the same across different runs, you can keep the seed value constant. If you don't care about reproducibility, you can omit the seed parameter or use a different value for each run.\n",
        "    shuffle=True,\n",
        "    image_size=Image_Size,\n",
        "    batch_size=batch_size,\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=None,\n",
        "    color_mode=\"rgb\",\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False\n",
        ")"
      ],
      "metadata": {
        "id": "ABdYGehOGoCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5371ba21-08b8-4436-c998-c25cbcf720e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5001 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = data_set.class_names\n",
        "class_names"
      ],
      "metadata": {
        "id": "bBgNkCViG9fL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b2786bd-3f3d-4e58-97a8-08a4014f4762"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Person 1',\n",
              " 'Person 10',\n",
              " 'Person 2',\n",
              " 'Person 3',\n",
              " 'Person 4',\n",
              " 'Person 5',\n",
              " 'Person 6',\n",
              " 'Person 7',\n",
              " 'Person 8',\n",
              " 'Person 9']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(data_set, train_split=0.8,  val_split=0.2, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + val_split ) == 1\n",
        "\n",
        "    ds_size = len(data_set)\n",
        "\n",
        "    if shuffle:\n",
        "        data_set = data_set.shuffle(shuffle_size, seed=123)\n",
        "\n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "\n",
        "    train_ds = data_set.take(train_size)\n",
        "    val_ds = data_set.skip(train_size).take(val_size)\n",
        "\n",
        "    return train_ds, val_ds\n",
        "\n",
        "\n",
        "\n",
        "train_ds, val_ds = get_dataset_partitions_tf(data_set)\n",
        "\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeR2nIUwpByc",
        "outputId": "ada973af-3768-4948-9e6f-ff4a08e09146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model= tf.keras.applications.resnet50.ResNet50(\n",
        "                include_top=False,\n",
        "                weights='imagenet',\n",
        "                input_tensor=None,\n",
        "                input_shape=input_shape,\n",
        "            )"
      ],
      "metadata": {
        "id": "80XMi1BWpQ6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff03d5b-4b9e-4a0d-c1b8-e8e26bbc5894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze the pre-trained layers\n",
        "# don't train existing weights\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "o5OQAdf-7zDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWIQB4wV8Bh_",
        "outputId": "0d11e1ff-f71f-4049-be5f-e880a5a8e7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 8, 8, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16777344  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40366346 (153.99 MB)\n",
            "Trainable params: 16778634 (64.01 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "n6NufCeg8GEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ACCURACY_THRESHOLD = 0.85\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        accuracy = logs.get('accuracy')  # Use 'accuracy' instead of 'acc'\n",
        "        if accuracy is not None and accuracy > ACCURACY_THRESHOLD:\n",
        "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" % (ACCURACY_THRESHOLD * 100))\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Instantiate a callback object\n",
        "early_stopping = myCallback()"
      ],
      "metadata": {
        "id": "SYxvcJw98QH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps=8,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h2n-L1U8HX9",
        "outputId": "d36fb8a2-2f67-4d4c-ed52-63b8a136ea5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 2540s 51s/step - loss: 4.2428 - accuracy: 0.7790 - val_loss: 0.2390 - val_accuracy: 0.9619\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9864 \n",
            "Reached 85.00% accuracy, so stopping training!!\n",
            "32/32 [==============================] - 1823s 51s/step - loss: 0.0700 - accuracy: 0.9864 - val_loss: 0.0050 - val_accuracy: 0.9971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/ML Trained Models/Dtect_Alternation_ResNet50_Model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKpzs5wT8VpT",
        "outputId": "977090bc-e2bc-42a6-979e-75d10a0b36cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/ML Trained Models/Dtect_Alternation_ResNet50_Model.h5')"
      ],
      "metadata": {
        "id": "UL_Hz-iBWpR2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def predict(model, img, class_names, confidence_threshold=0.5):\n",
        "    # Preprocess the image\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "\n",
        "    # Extract predicted class and confidence\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    confidence = predictions[0][predicted_class_index]\n",
        "    predicted_class = class_names[predicted_class_index]\n",
        "\n",
        "    # Check if confidence is high enough\n",
        "    if confidence >= confidence_threshold:\n",
        "        verification_status = \"verified\"\n",
        "    else:\n",
        "        verification_status = \"not verified\"\n",
        "\n",
        "    return predicted_class, confidence, verification_status"
      ],
      "metadata": {
        "id": "t3Vyz9siQ3AM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/ML Trained Models/Dtect_Alternation_ResNet50_Model.h5')\n",
        "\n",
        "# Define class names\n",
        "# Add your class names here\n",
        "\n",
        "# Load the image you want to predict\n",
        "img = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/T5.jpg', target_size=(256, 256))\n",
        "\n",
        "# Predict the image\n",
        "predicted_class, confidence, verification_status = predict(model, img, class_names)\n",
        "\n",
        "# Print the results\n",
        "print(\"Predicted class:\", predicted_class)\n",
        "print(\"Confidence:\", confidence)\n",
        "print(\"Verification status:\", verification_status)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_147Q-CQ7Gp",
        "outputId": "2e9794bb-4166-4d6a-d429-7417e974d56e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Predicted class: Person 2\n",
            "Confidence: 1.0\n",
            "Verification status: verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_signature(image_path):\n",
        "    # Preprocess the image\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=input_shape)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "    img_array /= 255.  # Normalize\n",
        "\n",
        "    # Classify the image\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    if predicted_class < 10:\n",
        "        return f\"Verified as class {predicted_class}\"\n",
        "    else:\n",
        "        return \"Not verified\"\n",
        "\n",
        "# Example usage\n",
        "image_path = '/content/drive/MyDrive/Kb_test.jpg'\n",
        "verification_result = verify_signature(image_path)\n",
        "print(verification_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFkTr85fSQTs",
        "outputId": "cbcb18e9-c916-467a-983d-3c427c44fbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 168ms/step\n",
            "Verified as class 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "def preprocess_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(256,256))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "# Function to make predictions on unseen images\n",
        "def predict_image(model, image_path):\n",
        "    img_array = preprocess_image(image_path)\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "    return predicted_class\n",
        "\n",
        "# Test on unseen images\n",
        "image_path = '/content/drive/MyDrive/orange3.jpg'\n",
        "predicted_class = predict_image(model, image_path)\n",
        "print('Predicted Class:', predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSMopGkITUrj",
        "outputId": "1579f885-f1c7-4435-b66f-2223bd399f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 232ms/step\n",
            "Predicted Class: [0]\n"
          ]
        }
      ]
    }
  ]
}