{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-M9rDnzbwMQkE81knixerKFn6zQu8Ga9",
      "authorship_tag": "ABX9TyM/IPk/iXORVF1RkMbkQIIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gobihanath/DTect/blob/main/Dtect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSS-NIPZHDwN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "input_shape = (512, 512, 3)    # 3 means the rgb format\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dataset from google drive"
      ],
      "metadata": {
        "id": "udchyiPLReMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DezADThWqQhY",
        "outputId": "9de575d8-fef1-457a-db6a-452b69be2dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image_Width = 512\n",
        "Image_Height = 512\n",
        "Image_Size = (Image_Width, Image_Height)\n",
        "Image_Channel = 3\n",
        "batch_size=20"
      ],
      "metadata": {
        "id": "aeFL0VqZ0kq6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Data Preprocessing**"
      ],
      "metadata": {
        "id": "TxCimNLQICOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"/content/drive/MyDrive/Dataset\",\n",
        "    seed=123,         #If you want to ensure that the shuffling of your dataset is the same across different runs, you can keep the seed value constant. If you don't care about reproducibility, you can omit the seed parameter or use a different value for each run.\n",
        "    shuffle=True,\n",
        "    image_size=Image_Size,\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "O5ngrE6tuEuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc8dcd3-9677-496c-a947-418780a80472"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 files belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(data_set)*.8)\n",
        "val_size = int(len(data_set)*.1)\n",
        "test_size = int(len(data_set)*.1)"
      ],
      "metadata": {
        "id": "1orrstodSnye"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size\n",
        "\n"
      ],
      "metadata": {
        "id": "zrBXF1ZgS-Zv",
        "outputId": "08648f60-5233-48c4-a500-9df8a4179bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Partition"
      ],
      "metadata": {
        "id": "QWMQI8sLfRmJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_partitions_tf(data_set, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "\n",
        "    ds_size = len(data_set)\n",
        "\n",
        "    if shuffle:\n",
        "        data_set = data_set.shuffle(shuffle_size, seed=12)\n",
        "\n",
        "    train_size = int(train_split * ds_size)\n",
        "    val_size = int(val_split * ds_size)\n",
        "\n",
        "    train_ds = data_set.take(train_size)\n",
        "    val_ds = data_set.skip(train_size).take(val_size)\n",
        "    test_ds = data_set.skip(train_size).skip(val_size)\n",
        "\n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "-Us96RStfMPU"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds, val_ds, test_ds = get_dataset_partitions_tf(data_set)\n",
        "\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))\n",
        "print(len(test_ds))"
      ],
      "metadata": {
        "id": "5tXv6X2wfN0i",
        "outputId": "c0da30b0-dfaf-4021-c76f-62f4aa11d417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "6\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training, Validation,Testing Data Preprocessing"
      ],
      "metadata": {
        "id": "j0SH-m3CfZJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=15,\n",
        "                                  rescale=1./255,\n",
        "                                  shear_range=0.1,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  width_shift_range=0.1,\n",
        "                                  height_shift_range=0.1,)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/My Drive/Dataset',\n",
        "                                              target_size=Image_Size,\n",
        "                                              batch_size=20,\n",
        "                                              class_mode = 'categorical')\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory('/content/drive/My Drive/Dataset',\n",
        "                                                  target_size=Image_Size,\n",
        "                                                  batch_size = 20,\n",
        "                                                  class_mode='categorical')"
      ],
      "metadata": {
        "id": "oMUEO5r82IBA",
        "outputId": "1d375690-10a2-4512-f88c-52936488c8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 images belonging to 6 classes.\n",
            "Found 1200 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building The CNN model"
      ],
      "metadata": {
        "id": "VoZ8U-VOEyrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# add convolutional layers with pooling and dropout\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# flatten the output and add dense layers with dropout\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#This is the output layer\n",
        "model.add(Dense(units=10, activation='softmax'))      #units=10 means we have 10 classes(signatures) softmax is used for\n",
        "\n",
        "# compile the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "gtQoICEME5P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training and Validation**"
      ],
      "metadata": {
        "id": "IR9giy8MRJ73"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peqakIPjRVP6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}